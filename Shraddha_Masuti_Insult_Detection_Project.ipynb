{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project on Detecting Insults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of the Project: To detect whether the online comment is an insult or not using machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have used Linear and Non-linear classifiers to test and have finalized the best classifier suited for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Numpy package\n",
    "import numpy as np\n",
    "# Import Pandas package\n",
    "import pandas as pd\n",
    "#Importing Scikit-learn to run the models\n",
    "import sklearn\n",
    "#To split data, import train_test_split and ShuffleSplit\n",
    "from sklearn.cross_validation import train_test_split, ShuffleSplit\n",
    "#For feature selection, import sklearn.feature_extraction.text\n",
    "import sklearn.feature_extraction.text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#For Naive Bayes\n",
    "import sklearn.naive_bayes as nb\n",
    "#For Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#For random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#For Support Vector machine\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Discovery and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test and train data to detect insults is downloaded from Kaggle. It contains 3947 observations, consisting of columns comments, date and its actual label. A label of 1 means its an insulting post, while a label of 0 represents not an insulting post. For Example, If the comment is  \"You fuck your dad.\" then Label would be 1; if the comment is “Yeah and where are you now?”, then Label would be: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the training file using pandas\n",
    "data = pd.read_csv(\"Data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3947, 3)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dataframe shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>1</td>\n",
       "      <td>20120502172717Z</td>\n",
       "      <td>\"you are both morons and that is never happening\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528164814Z</td>\n",
       "      <td>\"Many toolbars include spell check, like Yahoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620142813Z</td>\n",
       "      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528205648Z</td>\n",
       "      <td>\"How about Felix? He is sure turning into one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>20120515200734Z</td>\n",
       "      <td>\"You're all upset, defending this hipster band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult             Date  \\\n",
       "3942       1  20120502172717Z   \n",
       "3943       0  20120528164814Z   \n",
       "3944       0  20120620142813Z   \n",
       "3945       0  20120528205648Z   \n",
       "3946       0  20120515200734Z   \n",
       "\n",
       "                                                Comment  \n",
       "3942  \"you are both morons and that is never happening\"  \n",
       "3943  \"Many toolbars include spell check, like Yahoo...  \n",
       "3944  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...  \n",
       "3945  \"How about Felix? He is sure turning into one ...  \n",
       "3946  \"You're all upset, defending this hipster band...  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data\n",
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620171226Z</td>\n",
       "      <td>\"@SDL OK, but I would hope they'd sign him to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>20120503012628Z</td>\n",
       "      <td>\"Yeah and where are you now?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"shut the fuck up. you and the rest of your fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>20120502173553Z</td>\n",
       "      <td>\"Either you are fake or extremely stupid...may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20120620160512Z</td>\n",
       "      <td>\"That you are an idiot who understands neither...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620015140Z</td>\n",
       "      <td>\"@jdstorm dont wish him injury but it happened...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>20120530044519Z</td>\n",
       "      <td>\"Be careful,Jimbo.OG has a fork with your name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"@tonnyb  Or they just don't pay attention \"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Insult             Date                                            Comment\n",
       "0        1  20120618192155Z                               \"You fuck your dad.\"\n",
       "1        0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...\n",
       "2        0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3        0              NaN  \"listen if you dont wanna get married to a man...\n",
       "4        0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...\n",
       "5        0  20120620171226Z  \"@SDL OK, but I would hope they'd sign him to ...\n",
       "6        0  20120503012628Z                      \"Yeah and where are you now?\"\n",
       "7        1              NaN  \"shut the fuck up. you and the rest of your fa...\n",
       "8        1  20120502173553Z  \"Either you are fake or extremely stupid...may...\n",
       "9        1  20120620160512Z  \"That you are an idiot who understands neither...\n",
       "10       0  20120620015140Z  \"@jdstorm dont wish him injury but it happened...\n",
       "11       0  20120530044519Z  \"Be careful,Jimbo.OG has a fork with your name...\n",
       "12       0              NaN       \"@tonnyb  Or they just don't pay attention \""
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the top 10 rows of the dataset\n",
    "data.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insult</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2265</td>\n",
       "      <td>2898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>964</td>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Comment\n",
       "Insult               \n",
       "0       2265     2898\n",
       "1        964     1049"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the Count of Positive and Negative\n",
    "data.groupby('Insult').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting Labels and comments from the dataset\n",
    "insult_label, comments = data['Insult'],data['Comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, pandas.core.series.Series)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking type label and comments from the dataset\n",
    "type(insult_label), type(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Cleaning: To Lower Case\n",
    "# converting data to lowercase\n",
    "comments=comments.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"but how would you actually get the key out?\"'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.iloc[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking comment type\n",
    "type(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"dan_amd\\\\n\\\\n\\\\n\\\\n\\\\nyou have realy no clue on every single idiotic comment of all your posts.\\\\nwe all don\\'t enjoy your stupid pro amd b:u:l:l:s:h:i:t ignorance.\\\\nplease crawl back then in the fat ass of your gay loving buddy charlie\\\\ndemerjian semiinaccurate and try to find the light inside - u stupid fag!\\\\n\\\\n\\\\n\\\\n\\\\nwe realy don\\'t need and want your post here anymore!\"',\n",
       "  3),\n",
       " ('\"you\\'re an idiot\"', 3),\n",
       " ('\"faggot\"', 2),\n",
       " ('\"how old are you?\"', 2),\n",
       " ('\"fucking idiots\"', 2)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Counter package to count the most common sentences\n",
    "from collections import Counter\n",
    "c = Counter(comments)\n",
    "c.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk\n",
    "from nltk import sent_tokenize\n",
    "#RegularExpression\n",
    "import re\n",
    "from re import sub\n",
    "#Import String package to perform string operations\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer #for lemmatizing\n",
    "from nltk.stem.snowball import SnowballStemmer  #for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Text Cleaning, Removing all special characters\n",
    "def remove_special_char(x):\n",
    "# Replacing all punctuations with spaces\n",
    "    punc = string.punctuation.replace(\"-\", \"\")\n",
    "    punc = punc.replace(\"'\", \"\")\n",
    "    pat= r\"[{}]\".format(punc)\n",
    "    x=re.sub(pat, \" \", x)\n",
    "    # Replacing all digits with None\n",
    "    x=re.sub(pattern=r\"\\d\", repl=r\" \", string=x)\n",
    "    # Stripping extra white spaces\n",
    "    return \" \".join( i for i in stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shrad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming and Lemmatization\n",
    "def stemming(x):\n",
    "    st = WordNetLemmatizer()\n",
    "    words=x.strip().split()\n",
    "    st3=SnowballStemmer(\"english\")\n",
    "    return [st3.stem(st.lemmatize(x)) for x in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating copy of the transformed \n",
    "comments_transformed = comments.apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"i really don\\'t understand your point.\\\\xa0 it seems that you are mixing apples and oranges.\"'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the change\n",
    "comments.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you are a land creatur you would drown'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the change\n",
    "comments_transformed.iloc[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shrad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To Remove Stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# getting stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "type(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the length of stop words\n",
    "len(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3947, 11775)\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "tokens = text.TfidfVectorizer(stop_words=stopWords, ngram_range=(1, 1))\n",
    "D = tokens.fit_transform(comments_transformed)\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each sample has ~0.13% non-zero features\n"
     ]
    }
   ],
   "source": [
    "# checking the sparsity of matrix\n",
    "print(\"Each sample has ~{0:.2%} non-zero features\".format(D.nnz / float(D.shape[0] * D.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11775"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing words in vocab list\n",
    "vocab=list((tokens.vocabulary_).keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaaaaaaaa', 'aaaah', 'aaahhh', 'aac', 'aamir', 'aap', 'aarongmy', 'ab', 'abacha', 'abandon', 'abc', 'abe', 'abel', 'aberdeen', 'abet', 'abid', 'abigail', 'abil', 'ability', 'abit', 'abl', 'abnorm', 'abolish', 'abolit', 'abomin', 'abort', 'abortifaci', 'abortion', 'abov', 'abraham', 'abroad', 'abrupt', 'abscam', 'absenc', 'absolut', 'absolutejok', 'absolutely', 'abstain', 'abstractfirework', 'absurd', 'absurdum', 'absurt', 'aburrido', 'abus', 'abuse', 'abuses', 'abxxv', 'abysm', 'ac', 'academ']\n"
     ]
    }
   ],
   "source": [
    "vocab.sort()\n",
    "print(vocab[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Planning and Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will split the data set into train and test data in 75:25 ratio. Post which we will define the models like Decision Tree, Naive Bayes, Logistic Regression, Random forest and support vector machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing Data - Train and Validation\n",
    "(D_train, D_val,label_train, label_val) = train_test_split(D, insult_label, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2960, 11775)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking shape of train data\n",
    "D_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987, 11775)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking shape of value\n",
    "D_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression (LR)\n",
    "def model_LR():\n",
    "    # creating classifier\n",
    "    clf = LogisticRegression(tol=1e-8, penalty='l2', C=2)\n",
    "    # training classifier\n",
    "    clf.fit(D_train, label_train)\n",
    "    # model type\n",
    "    print(\"Model: \",type(clf))\n",
    "    # Predicting probabilities\n",
    "    p = clf.predict_proba(D_val)\n",
    "    return (clf.predict(D_val),p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine (SVM)\n",
    "def model_SVM():\n",
    "    # creating classifier\n",
    "    clf = svm.LinearSVC(penalty='l2', loss='squared_hinge',tol=1e-8)\n",
    "    # training classifier\n",
    "    clf.fit(D_train, label_train)\n",
    "    # model type\n",
    "    print(\"Model: \",type(clf))\n",
    "    return clf.predict(D_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes (NB)\n",
    "# Bernoulli Naive Baiyes\n",
    "def model_BernoulliNB():\n",
    "    # creating classifier\n",
    "    clf = nb.BernoulliNB(alpha=1.0, binarize=0.0)\n",
    "    # training classifier\n",
    "    clf.fit(D_train, label_train)\n",
    "    # model type\n",
    "    print(\"Model: \",type(clf))\n",
    "    # Predicting probabilities\n",
    "    p = clf.predict_proba(D_val)\n",
    "    return (clf.predict(D_val),p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linear Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "def model_RF():\n",
    "    # creating classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    # training classifier\n",
    "    clf.fit(D_train, label_train)\n",
    "    # model type\n",
    "    print(\"Model: \",type(clf))\n",
    "    # Predicting probabilities\n",
    "    p = clf.predict_proba(D_val)\n",
    "    return (clf.predict(D_val),p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier (DT)\n",
    "def model_DT():\n",
    "    # creating classifier\n",
    "    clf = DecisionTreeClassifier(max_depth=100)\n",
    "    # training classifier\n",
    "    clf.fit(D_train, label_train)\n",
    "    # model type\n",
    "    print(\"Model: \",type(clf))\n",
    "    # Predicting probabilities\n",
    "    p = clf.predict_proba(D_val)\n",
    "    return (clf.predict(D_val),p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing roc_auc_score for ROC and AUC score\n",
    "from sklearn.metrics import roc_auc_score as auc_score\n",
    "# Importing confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model,label_test):\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(label_test, model, labels=None, sample_weight=None)\n",
    "    tp, fn, fp, tn = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    precision= float(tp)/(tp+fp)\n",
    "    recall =  float(tp)/(tp+tn)\n",
    "    accuracy = np.mean(model == label_test)\n",
    "    print_results (precision, recall, accuracy)\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "def print_results (precision, recall, accuracy):\n",
    "    banner = \"Here is the classification report\"\n",
    "    print ('\\n',banner)\n",
    "    print ('=' * len(banner))\n",
    "    print ('{0:10s} {1:.1f}'.format('Precision',precision*100))\n",
    "    print ('{0:10s} {1:.1f}'.format('Recall',recall*100))\n",
    "    print ('{0:10s} {1:.1f}'.format('Accuracy',accuracy*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Precision, Recall and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "\n",
      " Here is the classification report\n",
      "=================================\n",
      "Precision  82.2\n",
      "Recall     88.2\n",
      "Accuracy   81.8\n",
      "AUC Score  86.7\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "# prediction of the model\n",
    "clf_LR, p = model_LR()\n",
    "# evaluating model\n",
    "acc_LR = model_evaluation(clf_LR, label_val)\n",
    "\n",
    "print ('{0:10s} {1:.1f}'.format('AUC Score',auc_score(label_val, p[:,1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'sklearn.svm.classes.LinearSVC'>\n",
      "\n",
      " Here is the classification report\n",
      "=================================\n",
      "Precision  85.0\n",
      "Recall     84.5\n",
      "Accuracy   83.1\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "# prediction of the model\n",
    "clf_SVM = model_SVM()\n",
    "# evaluating model\n",
    "acc_SVM = model_evaluation(clf_SVM, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'sklearn.naive_bayes.BernoulliNB'>\n",
      "\n",
      " Here is the classification report\n",
      "=================================\n",
      "Precision  77.4\n",
      "Recall     94.5\n",
      "Accuracy   76.2\n",
      "AUC Score  80.4\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "# prediction of the model\n",
    "clf_NB,p=model_BernoulliNB()\n",
    "# evaluating model\n",
    "acc_NB = model_evaluation(clf_NB, label_val)\n",
    "\n",
    "print ('{0:10s} {1:.1f}'.format('AUC Score',auc_score(label_val, p[:,1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "\n",
      " Here is the classification report\n",
      "=================================\n",
      "Precision  82.7\n",
      "Recall     87.3\n",
      "Accuracy   81.7\n",
      "AUC Score  82.9\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "# prediction of the model\n",
    "clf_RF,p=model_RF()\n",
    "# evaluating model\n",
    "acc_RF = model_evaluation(clf_RF, label_val)\n",
    "\n",
    "print ('{0:10s} {1:.1f}'.format('AUC Score',auc_score(label_val, p[:,1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      " Here is the classification report\n",
      "=================================\n",
      "Precision  84.8\n",
      "Recall     82.7\n",
      "Accuracy   78.4\n",
      "AUC Score  68.2\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "# prediction of the model\n",
    "clf_DT,p=model_DT()\n",
    "# evaluating model\n",
    "acc_DT = model_evaluation(clf_DT, label_val)\n",
    "\n",
    "print ('{0:10s} {1:.1f}'.format('AUC Score',auc_score(label_val, p[:,1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for all Models\n",
    "accuracy_model=[acc_LR, acc_SVM, acc_NB, acc_RF, acc_DT]\n",
    "accuracy_model=[('{0:2f}'.format(i*100)) for i in accuracy_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['81.762918', '83.080041', '76.190476', '81.661601', '78.419453']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation12(model,label_test):\n",
    "    # confusion matrix code\n",
    "    cm = confusion_matrix(label_test, model, labels=None, sample_weight=None)\n",
    "    tp, fn, fp, tn = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    recall =  float(tp)/(tp+tn)\n",
    "    #print_results (precision, recall, accuracy)\n",
    "    return recall\n",
    "recall_LR = model_evaluation12(clf_LR, label_val)\n",
    "recall_SVM = model_evaluation12(clf_SVM, label_val)\n",
    "recall_NB = model_evaluation12(clf_NB, label_val)\n",
    "recall_RF = model_evaluation12(clf_RF, label_val)\n",
    "recall_DT = model_evaluation12(clf_DT, label_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity for all Models\n",
    "sensitivity_model=[recall_LR, recall_SVM, recall_NB, recall_RF, recall_DT]\n",
    "sensitivity_model=[('{0:2f}'.format(i*100)) for i in sensitivity_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['88.228005', '84.512195', '94.547872', '87.344913', '82.687339']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy : 10-Fold Cross Validation\n",
    "# Logistic Regression\n",
    "clf1 = LogisticRegression(tol=1e-8, penalty='l2', C=2)\n",
    "# Support Vector Machines\n",
    "clf2 = svm.LinearSVC(penalty='l2', loss='squared_hinge')\n",
    "# Naive Bayes\n",
    "clf3 = nb.BernoulliNB(alpha=1.0, binarize=0.0)\n",
    "# Random Forest\n",
    "clf4 = RandomForestClassifier(n_estimators=100)\n",
    "# Decision Tree\n",
    "clf5 = DecisionTreeClassifier(max_depth=100)\n",
    "\n",
    "models=[clf1, clf2, clf3, clf4, clf5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy   81.1\n",
      "Accuracy   82.5\n",
      "Accuracy   75.1\n",
      "Accuracy   81.8\n",
      "Accuracy   78.5\n",
      "Normal Accuracy\n",
      "['81.762918', '83.080041', '76.190476', '81.661601', '78.419453']\n",
      "Accuracy post CV\n",
      "['81.1', '82.5', '75.1', '81.8', '78.5']\n"
     ]
    }
   ],
   "source": [
    "### Finding the accuracy of all the models, run the 10 fold cross validation and find the accuracy\n",
    "n_Folds = 10\n",
    "# Accuracy after cross validation:\n",
    "accuracy_cv=[]\n",
    "for clf in models:\n",
    "    accuracy_common=0\n",
    "    for test_run in range(n_Folds):\n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(D, insult_label, test_size=.2)\n",
    "        # call classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "        model=clf.predict(X_test)\n",
    "        # compare result\n",
    "        accuracy=np.mean(model == y_test)\n",
    "        # append to common\n",
    "        accuracy_common += accuracy\n",
    "        # final score\n",
    "    print ('{0:10s} {1:.1f}'.format('Accuracy',float(accuracy_common)/10*100))\n",
    "    accuracy_cv.append('{0:.1f}'.format(float(accuracy_common)/10*100))\n",
    "    \n",
    "print(\"Normal Accuracy\")\n",
    "print(accuracy_model)\n",
    "print(\"Accuracy post CV\")\n",
    "print(accuracy_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import plotly\n",
    "plotly.__version__\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking type of accuracy\n",
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy1=np.array(accuracy).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Visualization of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "rgb(190,98,221)",
          "line": {
           "color": "rgb(8,48,107)",
           "width": 1.5
          }
         },
         "text": [
          "81.762918",
          "83.080041",
          "76.190476",
          "81.661601",
          "78.419453"
         ],
         "textposition": "auto",
         "type": "bar",
         "uid": "ead310c5-0674-4bdf-8a29-5307d8a469d3",
         "x": [
          "Logistic",
          "SVM",
          "Naive Bayes",
          "Decion Tree",
          "Random Forest"
         ],
         "y": [
          "81.762918",
          "83.080041",
          "76.190476",
          "81.661601",
          "78.419453"
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"e1e7ac7b-be35-477d-8dee-a79edd7f1f53\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e1e7ac7b-be35-477d-8dee-a79edd7f1f53\", [{\"marker\": {\"color\": \"rgb(190,98,221)\", \"line\": {\"color\": \"rgb(8,48,107)\", \"width\": 1.5}}, \"text\": [\"81.762918\", \"83.080041\", \"76.190476\", \"81.661601\", \"78.419453\"], \"textposition\": \"auto\", \"x\": [\"Logistic\", \"SVM\", \"Naive Bayes\", \"Decion Tree\", \"Random Forest\"], \"y\": [\"81.762918\", \"83.080041\", \"76.190476\", \"81.661601\", \"78.419453\"], \"type\": \"bar\", \"uid\": \"53af4810-c40a-4d12-b4c3-c6abfc46d35d\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"e1e7ac7b-be35-477d-8dee-a79edd7f1f53\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"e1e7ac7b-be35-477d-8dee-a79edd7f1f53\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e1e7ac7b-be35-477d-8dee-a79edd7f1f53\", [{\"marker\": {\"color\": \"rgb(190,98,221)\", \"line\": {\"color\": \"rgb(8,48,107)\", \"width\": 1.5}}, \"text\": [\"81.762918\", \"83.080041\", \"76.190476\", \"81.661601\", \"78.419453\"], \"textposition\": \"auto\", \"x\": [\"Logistic\", \"SVM\", \"Naive Bayes\", \"Decion Tree\", \"Random Forest\"], \"y\": [\"81.762918\", \"83.080041\", \"76.190476\", \"81.661601\", \"78.419453\"], \"type\": \"bar\", \"uid\": \"53af4810-c40a-4d12-b4c3-c6abfc46d35d\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"e1e7ac7b-be35-477d-8dee-a79edd7f1f53\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot bar comparison of normal accuracy\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "normal = go.Bar(\n",
    "            x=['Logistic', 'SVM', 'Naive Bayes', 'Decion Tree', 'Random Forest'],\n",
    "            y= accuracy_model,\n",
    "            text=accuracy_model,\n",
    "            textposition = 'auto',\n",
    "            marker=dict(\n",
    "                color='rgb(190,98,221)',\n",
    "                line=dict(\n",
    "                color='rgb(8,48,107)',\n",
    "                width=1.5\n",
    "            )\n",
    "    )\n",
    ")\n",
    "data = [normal]\n",
    "iplot(data, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "rgb(95,208,224)",
          "line": {
           "color": "rgb(8,48,107)",
           "width": 1.5
          }
         },
         "text": [
          "81.1",
          "82.5",
          "75.1",
          "81.8",
          "78.5"
         ],
         "textposition": "auto",
         "type": "bar",
         "uid": "d76963ab-1cb7-4c82-b2d2-177d79085431",
         "x": [
          "Logistic",
          "SVM",
          "Naive Bayes",
          "Decion Tree",
          "Random Forest"
         ],
         "y": [
          "81.1",
          "82.5",
          "75.1",
          "81.8",
          "78.5"
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"35f59ef0-f439-45ac-a452-d92b29c532b6\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"35f59ef0-f439-45ac-a452-d92b29c532b6\", [{\"marker\": {\"color\": \"rgb(95,208,224)\", \"line\": {\"color\": \"rgb(8,48,107)\", \"width\": 1.5}}, \"text\": [\"81.1\", \"82.5\", \"75.1\", \"81.8\", \"78.5\"], \"textposition\": \"auto\", \"x\": [\"Logistic\", \"SVM\", \"Naive Bayes\", \"Decion Tree\", \"Random Forest\"], \"y\": [\"81.1\", \"82.5\", \"75.1\", \"81.8\", \"78.5\"], \"type\": \"bar\", \"uid\": \"5b3d19a3-0f7e-4cbe-9b6c-dbfbe5d880a0\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"35f59ef0-f439-45ac-a452-d92b29c532b6\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"35f59ef0-f439-45ac-a452-d92b29c532b6\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"35f59ef0-f439-45ac-a452-d92b29c532b6\", [{\"marker\": {\"color\": \"rgb(95,208,224)\", \"line\": {\"color\": \"rgb(8,48,107)\", \"width\": 1.5}}, \"text\": [\"81.1\", \"82.5\", \"75.1\", \"81.8\", \"78.5\"], \"textposition\": \"auto\", \"x\": [\"Logistic\", \"SVM\", \"Naive Bayes\", \"Decion Tree\", \"Random Forest\"], \"y\": [\"81.1\", \"82.5\", \"75.1\", \"81.8\", \"78.5\"], \"type\": \"bar\", \"uid\": \"5b3d19a3-0f7e-4cbe-9b6c-dbfbe5d880a0\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"35f59ef0-f439-45ac-a452-d92b29c532b6\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot bar comparison of cross validation accuracy\n",
    "data = [go.Bar(\n",
    "            x=['Logistic', 'SVM', 'Naive Bayes', 'Decion Tree', 'Random Forest'],\n",
    "            y= accuracy_cv,\n",
    "            text=accuracy_cv,\n",
    "            textposition = 'auto',\n",
    "    marker=dict(\n",
    "                color='rgb(95,208,224)',\n",
    "                line=dict(\n",
    "                color='rgb(8,48,107)',\n",
    "                width=1.5\n",
    "                )\n",
    "    )\n",
    "    )]\n",
    "iplot(data, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitivity of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "rgb(128,0,0)",
          "line": {
           "color": "rgb(8,48,107)",
           "width": 1.5
          }
         },
         "text": [
          "88.228005",
          "84.512195",
          "94.547872",
          "87.344913",
          "82.687339"
         ],
         "textposition": "auto",
         "type": "bar",
         "uid": "7a645125-6e76-4be9-ad73-eb115493cb79",
         "x": [
          "Logistic",
          "SVM",
          "Naive Bayes",
          "Decion Tree",
          "Random Forest"
         ],
         "y": [
          "88.228005",
          "84.512195",
          "94.547872",
          "87.344913",
          "82.687339"
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"5265e718-ae91-498e-8b55-967869c31572\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"5265e718-ae91-498e-8b55-967869c31572\", [{\"marker\": {\"color\": \"rgb(128,0,0)\", \"line\": {\"color\": \"rgb(8,48,107)\", \"width\": 1.5}}, \"text\": [\"88.228005\", \"84.512195\", \"94.547872\", \"87.344913\", \"82.687339\"], \"textposition\": \"auto\", \"x\": [\"Logistic\", \"SVM\", \"Naive Bayes\", \"Decion Tree\", \"Random Forest\"], \"y\": [\"88.228005\", \"84.512195\", \"94.547872\", \"87.344913\", \"82.687339\"], \"type\": \"bar\", \"uid\": \"1465ff78-4dfd-4891-8dac-4e45247279ae\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"5265e718-ae91-498e-8b55-967869c31572\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"5265e718-ae91-498e-8b55-967869c31572\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"5265e718-ae91-498e-8b55-967869c31572\", [{\"marker\": {\"color\": \"rgb(128,0,0)\", \"line\": {\"color\": \"rgb(8,48,107)\", \"width\": 1.5}}, \"text\": [\"88.228005\", \"84.512195\", \"94.547872\", \"87.344913\", \"82.687339\"], \"textposition\": \"auto\", \"x\": [\"Logistic\", \"SVM\", \"Naive Bayes\", \"Decion Tree\", \"Random Forest\"], \"y\": [\"88.228005\", \"84.512195\", \"94.547872\", \"87.344913\", \"82.687339\"], \"type\": \"bar\", \"uid\": \"1465ff78-4dfd-4891-8dac-4e45247279ae\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"5265e718-ae91-498e-8b55-967869c31572\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting bar comparison of sensitivity of all the models\n",
    "sensitivity = [go.Bar(\n",
    "            x=['Logistic', 'SVM', 'Naive Bayes', 'Decion Tree', 'Random Forest'],\n",
    "            y= sensitivity_model,\n",
    "            text=sensitivity_model,\n",
    "            textposition = 'auto',\n",
    "    marker=dict(\n",
    "                color='rgb(128,0,0)',\n",
    "                line=dict(\n",
    "                color='rgb(8,48,107)',\n",
    "                width=1.5\n",
    "                )\n",
    "    )\n",
    "    )]\n",
    "iplot(sensitivity, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Analysis on Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression:    Normal Accuracy: 82.28, Accuracy with 10 fold cross validation: 81.6,  Sensitivity:84.92\n",
    "Support Vector Machine: Normal Accuracy: 81.39, Accuracy with 10 fold cross validation: 83,  Sensitivity:81.96\n",
    "Random Forest:          Normal Accuracy: 79.75 Accuracy with 10 fold cross validation: 78.7, Sensitivity: 78.41\n",
    "\n",
    "Above three are the top 3 classifier results. The normal accuracy is high for logistic regression compared to Support Vector Machine and Random Forest.\n",
    "But accuracy with cross vlidation, Support vector machine is high. In case of sensitivity Logistic regression has the highest.\n",
    "\n",
    "Thus, combining the overall analysis, Logistic regression is best for the data, after which Support Vector Machine and Random Forest perform best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
